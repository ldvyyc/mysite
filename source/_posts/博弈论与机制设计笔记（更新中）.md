
---
title: 博弈论与机制设计笔记（更新中）
author: Frank Yu
categories: Learning
img: https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230317152434.png
toc: true
mathjax: true
cover: true
top: true
date: 2023-03-17, Friday
time: 15:21
tags: 
- GameTheory
- Notes
---

---

## Static Games of Complete Information

### Normal-form games

* Static: one shot, simultaneous move
* complete information: each player’s payof function is common knowledge among all players. 

##### Normal-form representation
* the players (参与者) in the game;
* the strategies (策略) available to each player;
* the payoff(收益/效用) received by each player for each combination of strategies that could be chosen by the players.

##### Normal-form Defination
The normal-form (标准式) (also called strategic-form) representation of an n-player game speciies the players' strategy sets/spaces $S_1$ , . . . , $S_n$ and their $\color{red}{payoff \quad functions}$ u1, . . . , un. We denote this game by



**Proof:**

Let A be an anti-symmetric payoff matrix of a two-player zero-sum game, and let v be the value of the game in pure strategies.

Suppose player I plays a mixed strategy p, and player II plays a mixed strategy q. Then the expected payoff of player I is given by:

$$\sum_{i,j} p_i q_j a_{i,j}$$

Since A is anti-symmetric, we have:

$$\sum_{i,j} p_i q_j a_{i,j} = \sum_{i,j} p_i q_j (-a_{j,i}) = -\sum_{i,j} p_j q_i a_{i,j}$$

Therefore, the expected payoff of player II is:

$$\sum_{i,j} p_j q_i a_{i,j}$$

So, the value of the game in mixed strategies is:

$$\min_{p}\max_{q}\sum_{i,j} p_i q_j a_{i,j} = \min_{p}\max_{q}-\sum_{i,j} p_j q_i a_{i,j} = -\max_{q}\min_{p}\sum_{i,j} p_j q_i a_{i,j} = 0$$

The first and third equalities follow from the definition of the value of the game, and the second equality follows from the anti-symmetry of A.

Since the value of the game in mixed strategies is 0, we know that there exists a pair of mixed strategies (p*, q*) such that the expected payoff of player I against q* is 0, and the expected payoff of player II against p* is 0. Thus, p* and q* are optimal strategies for both players.

Finally, note that the identification of Player I's pure strategy given by row k with Player II's pure strategy given by column k is equivalent to transposing A and exchanging the roles of the players. Since the value of the game is unchanged under this transformation, the set of optimal strategies for Player I is identical to that of Player II.

---

## Dynamic Games of Complete Information

### Intro

dynamic games: sequential choice or repeated play
Complete Information:  each player’s payof function is common knowledge among all players 

**center issue is credibility.**

* Use  extensive-form (扩展式) representation for dynamic games. 
* Draw game trees.

### Games of Perfect Information

![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316092735.png)
*an example of dynamic games of complete and perfect information*

Player 2 choose after he knows what player 1 choose.

If its imperfect Information, we draw a dotted line between 2 and 2 in the tree above.

**Note that**
* A2 may depend on the action a1, i.e., A2(a1).
* Some action a1 may even end the game, so that A2(a1) is an empty set (i.e., no choice of player 2).
* The action a1 is perfectly observed by player 2.

In the game of the farmer and the snake:
![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316093517.png)

##### Some key features
* the moves occur in sequence;
* all previous moves are observed before the next move ischosen
* the players’ payofs from each combination of moves are common knowledge.

#### Backwards Induction

* In the second stage, player 2 observes what player 1 choose and choose action to solving $$\max \limits_{a_2\in A_2}\quad u_2(a_1, a_2)$$
* Assume this optimization problem has a unique solution, denoted by $R_2(a_1)$.
	* This is player 2's best response to player 1's action $a_1$
* In the first stage, knowing player 2’s best response, player 1’s problem become$$\max \limits_{a_1\in A_1}\quad u_1(a_1, R_2(a_1))$$
* Assume it also has a unique solution, denoted by $a_1^*$.
* We call $(a_1, R_2(a_1^*))$ the backwards-induction outcome (逆向归纳的结果) of the game
* In the backwards-induction outcome, $a_1^*$ is determined by maximizing $u_1 (a_1 , R_2(a_1))$, and $a_2^* = R_2(a_1^*)$. 
* However, $a_1^*$ may not maximize $u_1(a_1, a_2^*)$.
![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316101111.png)



#### Stackelberg Model of Duopoly


Consider a dominant firm moving first and a follower moving second.
* The game is as follows:
	* Firm 1 choose quantity $q_1 \ge 0$
		* Firm 2 observes $q_1$ and then chooses a quantity $q_2 \ge 0$.
	* The payoff of firm i is the profit $$\pi_i\left(q_1, q_2\right)=q_i[P(Q)-c]$$where $Q=q_1+q_2$ and
$$
P(Q)= \begin{cases}a-Q, & \text { if } Q<a \\ 0, & \text { if } Q \geq a\end{cases}
$$


##### Now solve this game.
* First, find the best response function $R_2 (q_1)$ for firm 2, i.e.for any given $q_1$, find $q_2$ that solves $$\max _{q_2 \geq 0} \pi_2\left(q_1, q_2\right)$$where
$$\pi_2\left(q_1, q_2\right)= \begin{cases}q_2\left(a-q_1-q_2-c\right), & \text { if } q_1+q_2<a ; \\ -c q_2, & \text { if } q_1+q_2 \geq a .\end{cases}$$ 
* Then we have
$$
R_2\left(q_1\right)= \begin{cases}\frac{a-c-q_1}{2}, & \text { if } q_1<a-c \\ 0, & \text { if } q_1 \geq a-c .\end{cases}
$$
* $R_2(q_1)$ is the same as that in the Cournot model.
* Second, firm 1 knows $R_2 (q_1)$ and solves$$\max \limits_{q_1 \ge 0} \quad \pi_1(q_1, R_2(q_1))$$ where$$\pi_1\left(q_1, R_2\left(q_1\right)\right)= \begin{cases}q_1\left[a-q_1-\frac{a-q_1-c}{2}-c\right], & \text { if } q_1<a-c \\ q_1\left[a-q_1-c\right], & \text { if } a-c \leq q_1<a \\ -c q_1, & \text { if } q_1 \geq a\end{cases}$$
- Clearly, for $q_1>a-c$, firm 1's profit is always negative.
- Thus we only need to solve
$$
\max _{a-c \geq q_1 \geq 0} q_1\left[a-q_1-\frac{a-q_1-c}{2}-c\right],
$$
which leads to the following first-order condition
$$
a-c-2 q_1=0 .
$$
- The optimal choice of firm 1 is
$$
q_1^*=\frac{a-c}{2}
$$
- The quantity chosen by firm 2 is
$$
q_2^*=R_2\left(q_1^*\right)=\frac{a-c}{4} .
$$
- The market price is
$$
P^*=a-q_1^*-q_2^*=c+\frac{a-c}{4} .
$$
- Firms' profits and the total profit are
$$
\pi_1^*=\frac{(a-c)^2}{8}, \pi_2^*=\frac{(a-c)^2}{16}, \text { and } \Pi^*=\frac{3(a-c)^2}{16}
$$

##### Compare with Cournot Model
$$
\begin{aligned}
&\begin{array}{ccc}
\text {Variable} & \text{Cournot Model} & \text{Stackelberg Model}\\
\hline q_1^* & \frac{a-c}{3} & \frac{a-c}{2} \\
q_2^* & \frac{a-c}{3} & \frac{a-c}{4} \\
\pi_1^* & \frac{(a-c)^2}{9} & \frac{(a-c)^2}{8} \\
\pi_2^* & \frac{(a-c)^2}{9} & \frac{(a-c)^2}{16} \\
\Pi^* & \frac{2(a-c)^2}{9} & \frac{3(a-c)^2}{16} \\
P^* & c+\frac{a-c}{3} & c+\frac{a-c}{4} \\
\hline
\end{array}
\end{aligned}
$$

* Note: First-move advantage:
	* 先手有优势，比起同时的情况。


### Games of Imperfect Information

* Consider the following game
	* Players 1 and 2 simultaneously choose actions $a_1$ and $a_2$ from the feasible sets $A_1$ and $A_2$, respectively.
	* Players 3 and 4 observe the outcome of the first stage $(a_1 , a_2)$ and then simultaneously choose actions $a_3$ and $a_4$ from the feasible sets $A_3$ and $A_4$, respectively.
	* Payoffs are $u_i(a_1, a_2, a_3, a_4)$ for i = 1, 2, 3, 4. 
* **There are simultaneous moves within each stage.**

##### Solve
* Still, backwards induction.
- For each given $\left(a_1, a_2\right)$, players 3 and 4 try to find the Nash equilibrium in stage 2.
- Assume the second-stage game has a unique Nash equilibrium$$\left(a_3^*\left(a_1, a_2\right), a_4^*\left(a_1, a_2\right)\right)$$
- Then, player 1 and player 2 play a simultaneous-move game with payoffs$$
u_i\left(a_1, a_2, a_3^*\left(a_1, a_2\right), a_4^*\left(a_1, a_2\right)\right), \text { for } i=1,2$$
- Suppose $\left(a_1^*, a_2^*\right)$ is the unique Nash equilibrium of this simultaneous-move game.
- Then$$\left(a_1^*, a_2^*, a_3^*\left(a_1^*, a_2^*\right), a_4^*\left(a_1^*, a_2^*\right)\right)$$is the subgame-perfect outcome (子博弈精炼结果) of the two-stage game.

##### Example: Bank Run

* payoff in date 1:
* 
|          | Withdraw | Don't      |
| -------- | -------- | ---------- |
| **Withdraw** | 4,4      | 5,3        |
| **Don't**    | 3,5      | next stage |
* payoff in date 2
* |          | Withdraw | Don't      |
| -------- | -------- | ---------- |
| **Withdraw** | 8,8      | 11,5      |
| **Don't**    | 5,11      | 8,8 |

###### Solve: backwards

date2, both obtain 8 in nash equilibrium.
Thus, in date1, they play the following game:
* |          | Withdraw | Don't      |
| -------- | -------- | ---------- |
| **Withdraw** | 4,4      | 5,3        |
| **Don't**    | 3,5      | 8,8 |

There are two NE.




### Extensive-form Representation

##### Defination

The extensive-form (扩展式) representation of a game speciies:
* the players in the game;
* when each player has the move; *
* what each player can do at each of his or her opportunities to move; *
* what each player knows at each of his or her opportunities to move; *
* the payoffs received by each player for each combination of moves that could be chosen by the players
**the three * part describes strategies of each player in detail.**

use trees for extensive-form representations.
![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316110447.png)




#### Information Set

* Complete and perfect information
	* A dynamic game of complete and perfect information is a game in which the players move in sequence, all previous moves are observed before the next move is chosen, and payoffs are common knowledge. 
	* **Such games can be easily represented by a game tree.**
* Imperfect information
	*  some previous moves are not observed by the player with the current move. 
	* To present this kind of ignorance of previous moves and to describe what each player knows at each of his/her move, we introduce the notion of a player’s information set (信息集)

##### Definition of Information Set

An information set (信息集) for a player is a collection of decision nodes satisfying:
* The player needs to move at every node in the information set.
* When the play of the game reaches a node in the information set, the player with the move does not know which node in the set has (or has not) been reached.
	*  implies that the player must have the same set of feasible actions at each decision node in an information set; Otherwise the player could infer from the set of actions available that some node(s) had or had not been reached.
* **Any two nodes from different information sets of a player can be distinguished from each other.**

##### Application of Information Set

* A game is:
	* of perfect information (完美信息) if every information set is a singleton;
	* of imperfect information (不完美信息) if there is at least one non-singleton information set.
		* meaning there is at least a dotted line in the tree form.

Prisoners Dilemma
![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316113717.png)






#### Strategy

##### Definition
A strategy (策略) for a player is a complete plan of actions. It specifies a feasible action for the player in every contingency in which the player might be called on to act.
* For dynamic games with complete information: 
	* A player’s strategy is a function which assigns an action to each information set (not each decision node) belonging to the player. 
	* 对每个选择节点，指定一个策略
* An action and a strategy do not make a big diference in static games, while they do in dynamic games.

##### Example
![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316111235.png)
* Player 1 has 2 actions (and also 2 strategies): L and R. Player 2 has 2 actions: L′ and R′, but 4 strategies:$$(L^\prime, L^\prime); (L^\prime, R^\prime); (R^\prime, L^\prime); (R^\prime, R^\prime)$$
* For example, the strategy $(L^\prime, R^\prime)$ means:
	* if player 1 plays L, then player 2 plays $L^\prime$;
	* if player 1 plays R, then player 2 plays $R^\prime$.


### Subgame-perfect Nash Equilibrium

##### Question: how to represent this game in normal form?
![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230316111235.png)

* |          | $L^\prime L^\prime$ | $L^\prime R^\prime$      |$L^\prime L^\prime$| $L^\prime L^\prime$|
| --------     | -------- | ---------- | --- | --- |
| **L** | 3,1    | 3,1        |  1,2   | 1,2    |
| **R**    | 2,1      | 0,0 | 2,1    |  0,0   |
* there are two NE: ($L, R^\prime R^\prime$), ($R, R^\prime L^\prime$)

##### Interpret
* NE ($R, R^\prime L^\prime$)seems okay. It respects the spirit of backwards induction.
* NE ($L, R^\prime R^\prime$) has a problem: No matter which action is chosen by Player 1, player 2 must choose L′ at the right node. 
* **Interpretation: Player 2 tells player 1: if you choose R, I will choose R′ (threat), then each of us will get 0.** 
* This threat is non-creditable: Player 1 should not believe that player 2 will choose R′ after observing R. 
* Key: Ignorance of dynamic feature.


#### Subgame

###### Defination

* A subgame (子博弈) in an extensive-form game
	* begins at a decision node n that is a singleton information set (but is not the game’s initial node); 
	* includes all the decision and terminal nodes following node n in the game tree (but no nodes that do not follow n); 
	* does not cut any information sets (i.e., if a decision node n′ follows n in the game tree, then all other nodes in the information set containing n′ must also follow n, and so must be included in the subgame).
	* **只能从一个singleton的decision node节点切出来，并且不能把任何information set切断**

* When focus on a subgame, we shall only consider the relevant part of the strategy profile s. 
* Relevant part of s specifies the “complete” plans (or strategy profile) for the players in that subgame.

###### Example
![image.png](https://cdn.jsdelivr.net/gh/ldvyyc/ImgBed/20230317150643.png)

- We have a strategy profile $\left(L,\left(L^{\prime}, R^{\prime}\right),\left(L^{\prime \prime}, R^{\prime \prime}, R^{\prime \prime}, L^{\prime \prime}\right)\right)$.
- We turn to the subgame beginning at player 2's right decision node.
- The relevant part is $\left(R^{\prime},\left(R^{\prime \prime}, L^{\prime \prime}\right)\right)$ or $\left(-, R^{\prime},\left(R^{\prime \prime}, L^{\prime \prime}\right)\right)$. It is a strategy profile for this subgame.
	- We can discuss whether it is "reasonable", within this subgame.
- One can repeat this procedure for every subgame.

### Subgame-Perfect Nash Equilibrium
##### Definition

A Nash equilibrium is subgame-perfect (子博弈精炼), or is said to be a subgame-perfect Nash equilibrium (子博弈精炼均衡) if the players’ strategies constitute a Nash equilibrium in every subgame.

##### Application
* It can be shown that any finite dynamic game of complete information has a subgame-perfect Nash equilibrium, perhaps in mixed-strategies. 
* To find subgame-perfect Nash equilibria, 
	* we first need to find Nash equilibria in each subgame,
	* then use backwards-induction to solve for the whole game
* Subgame-perfect Nash equilibrium is closely related to two previous concepts:
	* 1 backwards-induction outcome;
	* 2 subgame-perfect outcome. 
	* 两者仅存在术语的差别，没有什么本质区别；混用没有问题。 
* What’s the diference between an equilibrium and an outcome? 
	* **An equilibrium is a collection of players’ strategies (strategy profile), while an outcome is a collection of players’ actions.**

##### Equilibrium vs. Outcome

* Example：
	- The backwards-induction outcome is $\left(a_1^*, R_2\left(a_1^*\right)\right)$.
	- The subgame-perfect Nash equilibrium is $\left(a_1^*, R_2(\cdot)\right)$.
	- Note that $R_2\left(a_1^*\right)$ is an action, while $R_2(\cdot)$ is a strategy for player 2.
- In Example 1:
	- $\left(R, L^{\prime}\right)$ is the backwards-induction outcome,
	- while $\left(R,\left(R^{\prime}, L^{\prime}\right)\right)$ is the subgame-perfect Nash equilibrium.
- In the Stackelberg model:
	- The backwards-induction outcome is $\left(q_1^*, q_2^*\right)$, where $q_1^*=\frac{a-c}{2}$ and $q_2^*=\frac{a-c}{4}$,
	- while the subgame-perfect Nash equilibrium is $\left(q_1^*, R_2\left(q_1\right)\right)$, where $R_2\left(q_1\right)=\frac{a-c-q_1}{2}$.
- For the two-stage game of complete but imperfect information
	* Then the subgame-perfect outcome is
$$
\left(a_1^*, a_2^*, a_3^*\left(a_1^*, a_2^*\right), a_4^*\left(a_1^*, a_2^*\right)\right) .
$$
	- The subgame-perfect Nash equilibrium is
$$
\left(a_1^*, a_2^*, a_3^*\left(a_1, a_2\right), a_4^*\left(a_1, a_2\right)\right) .
$$

##### Nash Equilibrium vs. Subgame-Perfect Nash Equilibrium

**A Nash equilibrium may not be subgame-perfect.**

* Following the example above.
	- The Nash equilibrium $\left(R,\left(R^{\prime}, L^{\prime}\right)\right)$ is subgame-perfect, because $R^{\prime}$ and $L^{\prime}$ are the optimal strategies in the left and right subgames, respectively, where player 2 is the only player.
	- On the other hand, the Nash equilibrium $\left(L,\left(R^{\prime}, R^{\prime}\right)\right)$ is not subgame-perfect, because when player 1 chooses $R, R^{\prime}$ is not optimal to player 2 in the right subgame, i.e., $R^{\prime}$ is not a Nash equilibrium in that subgame.
	- One can think the strategy $\left(R^{\prime}, R^{\prime}\right)$ by player 2 as a threat to player 1.
- Nash equilibria that rely on non-credible threats or promises can be eliminated by the requirement of subgame perfection.
- Subgame-perfect Nash equilibrium is a refinement of Nash equilibrium, i.e.,
	$\{$ Subgame-perfect Nash equilibria $\} \subseteq\{$ Nash equilibria $\}$


### Summary

- We have considered dynamic games of complete information.
- Two basic questions:
	* How to describe a dynamic situation $\rightarrow$ extensive-form representation.
	* How to solve a dynamic game? Why to introduce SPNE?
- Backwards induction vs. SPNE.
- 静态场景 $\rightarrow$ 静态模型 $\rightarrow$ 标准式
	* 静态场景 $\rightarrow$ 动态模型 (带有不完美信息) $\rightarrow$ 扩展式 (没有 失去场景的特点)
- 动态场景 $\rightarrow$ 动态模型 $\rightarrow$ 扩展式
	* 动态场景 $\rightarrow$ 静态模型 $\rightarrow$ 标准式 (失去场景的动态特点)